# Management and documentation of data collection, preparation, feature engineering and selection

* Data Collection
  * Sources of Data: Internal vs. External data, APIs, surveys, sensors, etc.
  * Data Types: Structured, unstructured, time-series, categorical, continuous
  * Tools & Techniques: Data scraping, database querying, data ingestion from files (CSV, JSON, etc.)
  * Documentation Best Practices: Version control for datasets, data collection methodologies, metadata
  * Challenges: Missing data, data consistency, data quality

* Data Preparation
  * Data Cleaning: Handling missing values, removing duplicates, dealing with outliers
  * Data Transformation: Normalization, scaling, encoding categorical variables
  * Splitting the Dataset: Training, validation, and test sets
  * Documentation Best Practices: Tracking data cleaning methods, transformations applied, scripts used for preprocessing
  * Tools: Pandas, NumPy, scikit-learn
* Feature Engineering
  *Feature Creation: Creating new features from raw data, aggregation, extraction, and transformation
  Feature Encoding: Techniques for categorical features, such as one-hot encoding, label encoding
  Dimensionality Reduction: Principal Component Analysis (PCA), t-SNE for feature visualization
  Tools: Featuretools, scikit-learn, custom scripts
  Documentation Best Practices: Documenting feature definitions, rationale for transformations, tools/scripts used
* Feature Selection
